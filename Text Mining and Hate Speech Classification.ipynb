{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining and Hate Speech Classification\n",
    "Kali ini kita akan melakukan klasifikasi *hate speech* untuk menghasilkan model yang dapat menentukan apakah sebuah *tweet* merupakan *hate speech* atau bukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>HS</td>\n",
       "      <td>Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>HS</td>\n",
       "      <td>Betul bang hancurkan merka bang, musnahkan chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>HS</td>\n",
       "      <td>Sapa Yg bilang Ahok anti korupsi!?, klo grombo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>HS</td>\n",
       "      <td>Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>HS</td>\n",
       "      <td>Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet\n",
       "0    Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...\n",
       "1    Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...\n",
       "2    Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...\n",
       "3    Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...\n",
       "4    Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P...\n",
       "..      ...                                                ...\n",
       "708      HS  Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....\n",
       "709      HS  Betul bang hancurkan merka bang, musnahkan chi...\n",
       "710      HS  Sapa Yg bilang Ahok anti korupsi!?, klo grombo...\n",
       "711      HS  Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...\n",
       "712      HS  Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...\n",
       "\n",
       "[713 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'https://raw.githubusercontent.com/ialfina/id-hatespeech-detection/master/IDHSD_RIO_unbalanced_713_2017.txt', sep='\\t', header=None, names=['label', 'tweet'], skiprows=1, engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Berbeda dengan kasus pada proyek sebelumnya, kali ini kolom *tweet* berisi teks yang harus diolah sedemikian rupa sehingga dapat dimengerti oleh komputer. Pertama, mari kita impor *library* yang akan digunakan untuk memproses teks dalam Bahasa Indonesia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nitro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "Merupakan metode untuk memecah sebuah kalimat menjadi kata-kata. Hal ini perlu dilakukan karena untuk mesin, lebih mudah memproses kata-kata dibandingkan kalimat. Selain itu, kita juga akan mengubah semua huruf kapital menjadi huruf kecil serta menghilangkan simbol yang tidak diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @spardaxyz: Fadli Zon Minta Mendagri Segera Menonaktifkan Ahok Jadi Gubernur DKI https:\\/\\/t.co\\/KH5vIRwPdO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@',\n",
       " 'spardaxyz',\n",
       " ':',\n",
       " 'Fadli',\n",
       " 'Zon',\n",
       " 'Minta',\n",
       " 'Mendagri',\n",
       " 'Segera',\n",
       " 'Menonaktifkan',\n",
       " 'Ahok',\n",
       " 'Jadi',\n",
       " 'Gubernur',\n",
       " 'DKI',\n",
       " 'https',\n",
       " ':',\n",
       " '\\\\/\\\\/t.co\\\\/KH5vIRwPdO']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before\n",
    "print(df['tweet'][0])\n",
    "nltk.word_tokenize(df[\"tweet\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "      <td>[RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "      <td>[RT, @, baguscondromowo, :, Mereka, terus, mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "      <td>[Sylvi, :, bagaimana, gurbernur, melakukan, ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "      <td>[Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "      <td>[RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>HS</td>\n",
       "      <td>Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....</td>\n",
       "      <td>[Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>HS</td>\n",
       "      <td>Betul bang hancurkan merka bang, musnahkan chi...</td>\n",
       "      <td>[Betul, bang, hancurkan, merka, bang, ,, musna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>HS</td>\n",
       "      <td>Sapa Yg bilang Ahok anti korupsi!?, klo grombo...</td>\n",
       "      <td>[Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>HS</td>\n",
       "      <td>Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...</td>\n",
       "      <td>[Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>HS</td>\n",
       "      <td>Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...</td>\n",
       "      <td>[Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet  \\\n",
       "0    Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...   \n",
       "1    Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...   \n",
       "2    Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...   \n",
       "3    Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...   \n",
       "4    Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P...   \n",
       "..      ...                                                ...   \n",
       "708      HS  Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....   \n",
       "709      HS  Betul bang hancurkan merka bang, musnahkan chi...   \n",
       "710      HS  Sapa Yg bilang Ahok anti korupsi!?, klo grombo...   \n",
       "711      HS  Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...   \n",
       "712      HS  Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...   \n",
       "\n",
       "                                             tokenized  \n",
       "0    [RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...  \n",
       "1    [RT, @, baguscondromowo, :, Mereka, terus, mel...  \n",
       "2    [Sylvi, :, bagaimana, gurbernur, melakukan, ke...  \n",
       "3    [Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...  \n",
       "4    [RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....  \n",
       "..                                                 ...  \n",
       "708  [Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...  \n",
       "709  [Betul, bang, hancurkan, merka, bang, ,, musna...  \n",
       "710  [Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...  \n",
       "711  [Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...  \n",
       "712  [Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...  \n",
       "\n",
       "[713 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memecah kalimat\n",
    "df['tokenized'] = df.apply(lambda row: nltk.word_tokenize(row['tweet']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_nosymbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "      <td>[RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...</td>\n",
       "      <td>[rt, spardaxyz, fadli, zon, minta, mendagri, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "      <td>[RT, @, baguscondromowo, :, Mereka, terus, mel...</td>\n",
       "      <td>[rt, baguscondromowo, mereka, terus, melukai, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "      <td>[Sylvi, :, bagaimana, gurbernur, melakukan, ke...</td>\n",
       "      <td>[sylvi, bagaimana, gurbernur, melakukan, keker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "      <td>[Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...</td>\n",
       "      <td>[ahmad, dhani, tak, puas, debat, pilkada, masa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "      <td>[RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....</td>\n",
       "      <td>[rt, waspada, ktp, palsu, pilkada, https]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>HS</td>\n",
       "      <td>Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....</td>\n",
       "      <td>[Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...</td>\n",
       "      <td>[muka, si, babi, ahok, tuh, yg, mirip, serbet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>HS</td>\n",
       "      <td>Betul bang hancurkan merka bang, musnahkan chi...</td>\n",
       "      <td>[Betul, bang, hancurkan, merka, bang, ,, musna...</td>\n",
       "      <td>[betul, bang, hancurkan, merka, bang, musnahka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>HS</td>\n",
       "      <td>Sapa Yg bilang Ahok anti korupsi!?, klo grombo...</td>\n",
       "      <td>[Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...</td>\n",
       "      <td>[sapa, yg, bilang, ahok, anti, korupsi, klo, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>HS</td>\n",
       "      <td>Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...</td>\n",
       "      <td>[Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...</td>\n",
       "      <td>[gw, juga, ngimpi, sentilin, biji, babi, ahok,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>HS</td>\n",
       "      <td>Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...</td>\n",
       "      <td>[Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...</td>\n",
       "      <td>[gw, ketemu, sama, si, babi, iwan, bopeng, di,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet  \\\n",
       "0    Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...   \n",
       "1    Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...   \n",
       "2    Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...   \n",
       "3    Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...   \n",
       "4    Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P...   \n",
       "..      ...                                                ...   \n",
       "708      HS  Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....   \n",
       "709      HS  Betul bang hancurkan merka bang, musnahkan chi...   \n",
       "710      HS  Sapa Yg bilang Ahok anti korupsi!?, klo grombo...   \n",
       "711      HS  Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...   \n",
       "712      HS  Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "0    [RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...   \n",
       "1    [RT, @, baguscondromowo, :, Mereka, terus, mel...   \n",
       "2    [Sylvi, :, bagaimana, gurbernur, melakukan, ke...   \n",
       "3    [Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...   \n",
       "4    [RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....   \n",
       "..                                                 ...   \n",
       "708  [Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...   \n",
       "709  [Betul, bang, hancurkan, merka, bang, ,, musna...   \n",
       "710  [Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...   \n",
       "711  [Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...   \n",
       "712  [Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...   \n",
       "\n",
       "                                    tokenized_nosymbol  \n",
       "0    [rt, spardaxyz, fadli, zon, minta, mendagri, s...  \n",
       "1    [rt, baguscondromowo, mereka, terus, melukai, ...  \n",
       "2    [sylvi, bagaimana, gurbernur, melakukan, keker...  \n",
       "3    [ahmad, dhani, tak, puas, debat, pilkada, masa...  \n",
       "4            [rt, waspada, ktp, palsu, pilkada, https]  \n",
       "..                                                 ...  \n",
       "708  [muka, si, babi, ahok, tuh, yg, mirip, serbet,...  \n",
       "709  [betul, bang, hancurkan, merka, bang, musnahka...  \n",
       "710  [sapa, yg, bilang, ahok, anti, korupsi, klo, g...  \n",
       "711  [gw, juga, ngimpi, sentilin, biji, babi, ahok,...  \n",
       "712  [gw, ketemu, sama, si, babi, iwan, bopeng, di,...  \n",
       "\n",
       "[713 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menghapus simbol\n",
    "df['tokenized_nosymbol'] = df['tokenized']\n",
    "for i in range(0, len(df)):\n",
    "    words = df['tokenized'][i]\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    df['tokenized_nosymbol'][i] = words\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'spardaxyz',\n",
       " 'fadli',\n",
       " 'zon',\n",
       " 'minta',\n",
       " 'mendagri',\n",
       " 'segera',\n",
       " 'menonaktifkan',\n",
       " 'ahok',\n",
       " 'jadi',\n",
       " 'gubernur',\n",
       " 'dki',\n",
       " 'https']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after\n",
    "df['tokenized_nosymbol'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Dilakukan untuk menghilangkan imbuhan atau awalan dari tiap katanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'baguscondromowo',\n",
       " 'mereka',\n",
       " 'terus',\n",
       " 'melukai',\n",
       " 'aksi',\n",
       " 'dalam',\n",
       " 'rangka',\n",
       " 'memenjarakan',\n",
       " 'ahok',\n",
       " 'atau',\n",
       " 'ahok',\n",
       " 'gagal',\n",
       " 'dalam',\n",
       " 'pilkada']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before\n",
    "df['tokenized_nosymbol'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_nosymbol</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @spardaxyz: Fadli Zon Minta Mendagri Segera...</td>\n",
       "      <td>[RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...</td>\n",
       "      <td>[rt, spardaxyz, fadli, zon, minta, mendagri, s...</td>\n",
       "      <td>[rt, spardaxyz, fadli, zon, minta, mendagri, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @baguscondromowo: Mereka terus melukai aksi...</td>\n",
       "      <td>[RT, @, baguscondromowo, :, Mereka, terus, mel...</td>\n",
       "      <td>[rt, baguscondromowo, mereka, terus, melukai, ...</td>\n",
       "      <td>[rt, baguscondromowo, mereka, terus, luka, aks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Sylvi: bagaimana gurbernur melakukan kekerasan...</td>\n",
       "      <td>[Sylvi, :, bagaimana, gurbernur, melakukan, ke...</td>\n",
       "      <td>[sylvi, bagaimana, gurbernur, melakukan, keker...</td>\n",
       "      <td>[sylvi, bagaimana, gurbernur, laku, keras, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...</td>\n",
       "      <td>[Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...</td>\n",
       "      <td>[ahmad, dhani, tak, puas, debat, pilkada, masa...</td>\n",
       "      <td>[ahmad, dhani, tak, puas, debat, pilkada, masa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Non_HS</td>\n",
       "      <td>RT @lisdaulay28: Waspada KTP palsu.....kawal P...</td>\n",
       "      <td>[RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....</td>\n",
       "      <td>[rt, waspada, ktp, palsu, pilkada, https]</td>\n",
       "      <td>[rt, waspada, ktp, palsu, pilkada, https]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>HS</td>\n",
       "      <td>Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....</td>\n",
       "      <td>[Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...</td>\n",
       "      <td>[muka, si, babi, ahok, tuh, yg, mirip, serbet,...</td>\n",
       "      <td>[muka, si, babi, ahok, tuh, yg, mirip, serbet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>HS</td>\n",
       "      <td>Betul bang hancurkan merka bang, musnahkan chi...</td>\n",
       "      <td>[Betul, bang, hancurkan, merka, bang, ,, musna...</td>\n",
       "      <td>[betul, bang, hancurkan, merka, bang, musnahka...</td>\n",
       "      <td>[betul, bang, hancur, merka, bang, musnah, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>HS</td>\n",
       "      <td>Sapa Yg bilang Ahok anti korupsi!?, klo grombo...</td>\n",
       "      <td>[Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...</td>\n",
       "      <td>[sapa, yg, bilang, ahok, anti, korupsi, klo, g...</td>\n",
       "      <td>[sapa, yg, bilang, ahok, anti, korupsi, klo, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>HS</td>\n",
       "      <td>Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...</td>\n",
       "      <td>[Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...</td>\n",
       "      <td>[gw, juga, ngimpi, sentilin, biji, babi, ahok,...</td>\n",
       "      <td>[gw, juga, ngimpi, sentilin, biji, babi, ahok,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>HS</td>\n",
       "      <td>Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...</td>\n",
       "      <td>[Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...</td>\n",
       "      <td>[gw, ketemu, sama, si, babi, iwan, bopeng, di,...</td>\n",
       "      <td>[gw, ketemu, sama, si, babi, iwan, bopeng, di,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet  \\\n",
       "0    Non_HS  RT @spardaxyz: Fadli Zon Minta Mendagri Segera...   \n",
       "1    Non_HS  RT @baguscondromowo: Mereka terus melukai aksi...   \n",
       "2    Non_HS  Sylvi: bagaimana gurbernur melakukan kekerasan...   \n",
       "3    Non_HS  Ahmad Dhani Tak Puas Debat Pilkada, Masalah Ja...   \n",
       "4    Non_HS  RT @lisdaulay28: Waspada KTP palsu.....kawal P...   \n",
       "..      ...                                                ...   \n",
       "708      HS  Muka Si BABi Ahok Tuh Yg Mirip SERBET Lantai.....   \n",
       "709      HS  Betul bang hancurkan merka bang, musnahkan chi...   \n",
       "710      HS  Sapa Yg bilang Ahok anti korupsi!?, klo grombo...   \n",
       "711      HS  Gw juga ngimpi SENTILIN BIJI BABI AHOK, pcetar...   \n",
       "712      HS  Mudah2an gw ketemu sama SI BABI IWAN BOPENG DI...   \n",
       "\n",
       "                                             tokenized  \\\n",
       "0    [RT, @, spardaxyz, :, Fadli, Zon, Minta, Menda...   \n",
       "1    [RT, @, baguscondromowo, :, Mereka, terus, mel...   \n",
       "2    [Sylvi, :, bagaimana, gurbernur, melakukan, ke...   \n",
       "3    [Ahmad, Dhani, Tak, Puas, Debat, Pilkada, ,, M...   \n",
       "4    [RT, @, lisdaulay28, :, Waspada, KTP, palsu, ....   \n",
       "..                                                 ...   \n",
       "708  [Muka, Si, BABi, Ahok, Tuh, Yg, Mirip, SERBET,...   \n",
       "709  [Betul, bang, hancurkan, merka, bang, ,, musna...   \n",
       "710  [Sapa, Yg, bilang, Ahok, anti, korupsi, !, ?, ...   \n",
       "711  [Gw, juga, ngimpi, SENTILIN, BIJI, BABI, AHOK,...   \n",
       "712  [Mudah2an, gw, ketemu, sama, SI, BABI, IWAN, B...   \n",
       "\n",
       "                                    tokenized_nosymbol  \\\n",
       "0    [rt, spardaxyz, fadli, zon, minta, mendagri, s...   \n",
       "1    [rt, baguscondromowo, mereka, terus, melukai, ...   \n",
       "2    [sylvi, bagaimana, gurbernur, melakukan, keker...   \n",
       "3    [ahmad, dhani, tak, puas, debat, pilkada, masa...   \n",
       "4            [rt, waspada, ktp, palsu, pilkada, https]   \n",
       "..                                                 ...   \n",
       "708  [muka, si, babi, ahok, tuh, yg, mirip, serbet,...   \n",
       "709  [betul, bang, hancurkan, merka, bang, musnahka...   \n",
       "710  [sapa, yg, bilang, ahok, anti, korupsi, klo, g...   \n",
       "711  [gw, juga, ngimpi, sentilin, biji, babi, ahok,...   \n",
       "712  [gw, ketemu, sama, si, babi, iwan, bopeng, di,...   \n",
       "\n",
       "                                               stemmed  \n",
       "0    [rt, spardaxyz, fadli, zon, minta, mendagri, s...  \n",
       "1    [rt, baguscondromowo, mereka, terus, luka, aks...  \n",
       "2    [sylvi, bagaimana, gurbernur, laku, keras, per...  \n",
       "3    [ahmad, dhani, tak, puas, debat, pilkada, masa...  \n",
       "4            [rt, waspada, ktp, palsu, pilkada, https]  \n",
       "..                                                 ...  \n",
       "708  [muka, si, babi, ahok, tuh, yg, mirip, serbet,...  \n",
       "709  [betul, bang, hancur, merka, bang, musnah, chi...  \n",
       "710  [sapa, yg, bilang, ahok, anti, korupsi, klo, g...  \n",
       "711  [gw, juga, ngimpi, sentilin, biji, babi, ahok,...  \n",
       "712  [gw, ketemu, sama, si, babi, iwan, bopeng, di,...  \n",
       "\n",
       "[713 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "df['stemmed'] = df['tweet']\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    stemmed = []\n",
    "    for j in range(0, len(df['tokenized_nosymbol'][i])):\n",
    "        stemmed.append(stemmer.stem(df['tokenized_nosymbol'][i][j]))\n",
    "    df['stemmed'][i] = stemmed\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'baguscondromowo',\n",
       " 'mereka',\n",
       " 'terus',\n",
       " 'luka',\n",
       " 'aksi',\n",
       " 'dalam',\n",
       " 'rangka',\n",
       " 'penjara',\n",
       " 'ahok',\n",
       " 'atau',\n",
       " 'ahok',\n",
       " 'gagal',\n",
       " 'dalam',\n",
       " 'pilkada']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after\n",
    "df['stemmed'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "Mengubah list pada kolom *stemmed* menjadi biner. Hanya akan dilakukan pada kolom *stemming*, agar bisa dilakukan bersamaan dengan menentukan fitur dan target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>aagym</th>\n",
       "      <th>aahhh</th>\n",
       "      <th>aamiin</th>\n",
       "      <th>abai</th>\n",
       "      <th>abang</th>\n",
       "      <th>abdi</th>\n",
       "      <th>abis</th>\n",
       "      <th>abu</th>\n",
       "      <th>acara</th>\n",
       "      <th>...</th>\n",
       "      <th>yme</th>\n",
       "      <th>yng</th>\n",
       "      <th>yoi</th>\n",
       "      <th>yos</th>\n",
       "      <th>you</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yudijannis</th>\n",
       "      <th>yuk</th>\n",
       "      <th>zikir</th>\n",
       "      <th>zon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows Ã— 2330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  aagym  aahhh  aamiin  abai  abang  abdi  abis  abu  acara  ...  yme  \\\n",
       "0    0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "1    0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "2    0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "3    0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "4    0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "..  ..    ...    ...     ...   ...    ...   ...   ...  ...    ...  ...  ...   \n",
       "708  0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "709  0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "710  0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "711  0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "712  0      0      0       0     0      0     0     0    0      0  ...    0   \n",
       "\n",
       "     yng  yoi  yos  you  youtube  yudijannis  yuk  zikir  zon  \n",
       "0      0    0    0    0        0           0    0      0    1  \n",
       "1      0    0    0    0        0           0    0      0    0  \n",
       "2      0    0    0    0        0           0    0      0    0  \n",
       "3      0    0    0    0        0           0    0      0    0  \n",
       "4      0    0    0    0        0           0    0      0    0  \n",
       "..   ...  ...  ...  ...      ...         ...  ...    ...  ...  \n",
       "708    0    0    0    0        0           0    0      0    0  \n",
       "709    0    0    0    0        0           0    0      0    0  \n",
       "710    0    0    0    0        0           0    0      0    0  \n",
       "711    0    0    0    0        0           0    0      0    0  \n",
       "712    0    0    0    0        0           0    0      0    0  \n",
       "\n",
       "[713 rows x 2330 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = df['stemmed'].str.join('|').str.get_dummies()\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Non_HS\n",
       "1      Non_HS\n",
       "2      Non_HS\n",
       "3      Non_HS\n",
       "4      Non_HS\n",
       "        ...  \n",
       "708        HS\n",
       "709        HS\n",
       "710        HS\n",
       "711        HS\n",
       "712        HS\n",
       "Name: label, Length: 713, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['label']\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "Akan digunakan beberapa model untuk mencari model yang terbaik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Untuk melatih model, dataframe akan dipecah menjadi 70% data untuk *training* dan 30% data untuk *testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 2330)\n",
      "(214, 2330)\n",
      "(499,)\n",
      "(214,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test  = train_test_split(feature , target, shuffle = True, test_size=0.3, random_state=1)\n",
    "\n",
    "# Show the Training and Testing Data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'HS',\n",
       "       'Non_HS', 'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Module\n",
    "from sklearn import tree, metrics\n",
    "\n",
    "# Modeling Decision Tree\n",
    "dtc = tree.DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Predict to Test Data \n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "y_pred_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8177570093457944\n",
      "Precision: 0.8688524590163934\n",
      "Recall: 0.6309523809523809\n",
      "F1 Score: 0.7310344827586208\n",
      "Cohens Kappa Score: 0.5984024636704841\n"
     ]
    }
   ],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_dtc = metrics.accuracy_score(y_test, y_pred_dtc)\n",
    "prec_dtc = metrics.precision_score(y_test, y_pred_dtc, pos_label = 'HS')\n",
    "rec_dtc = metrics.recall_score(y_test, y_pred_dtc, pos_label = 'HS')\n",
    "f1_dtc = metrics.f1_score(y_test, y_pred_dtc, pos_label = 'HS')\n",
    "kappa_dtc = metrics.cohen_kappa_score(y_test, y_pred_dtc)\n",
    "\n",
    "print(\"Accuracy:\", acc_dtc)\n",
    "print(\"Precision:\", prec_dtc)\n",
    "print(\"Recall:\", rec_dtc)\n",
    "print(\"F1 Score:\", f1_dtc)\n",
    "print(\"Cohens Kappa Score:\", kappa_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "# Modeling Naive Bayes Classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict to Test Data\n",
    "y_pred_gnb= gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7523364485981309\n",
      "Precision: 0.6534653465346535\n",
      "Recall: 0.7857142857142857\n",
      "F1 Score: 0.7135135135135134\n",
      "Cohens Kappa Score: 0.4986296525506144\n"
     ]
    }
   ],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_gnb = metrics.accuracy_score(y_test, y_pred_gnb)\n",
    "prec_gnb = metrics.precision_score(y_test, y_pred_gnb, pos_label = 'HS')\n",
    "rec_gnb = metrics.recall_score(y_test, y_pred_gnb, pos_label = 'HS')\n",
    "f1_gnb = metrics.f1_score(y_test, y_pred_gnb, pos_label = 'HS')\n",
    "kappa_gnb = metrics.cohen_kappa_score(y_test, y_pred_gnb)\n",
    "\n",
    "print(\"Accuracy:\", acc_gnb)\n",
    "print(\"Precision:\", prec_gnb)\n",
    "print(\"Recall:\", rec_gnb)\n",
    "print(\"F1 Score:\", f1_gnb)\n",
    "print(\"Cohens Kappa Score:\", kappa_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'HS',\n",
       "       'Non_HS', 'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'HS',\n",
       "       'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS',\n",
       "       'HS', 'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'HS', 'HS',\n",
       "       'Non_HS', 'Non_HS', 'HS', 'Non_HS', 'Non_HS', 'Non_HS', 'Non_HS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modeling Decision Tree\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict to Test Data \n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8317757009345794\n",
      "Precision: 0.9\n",
      "Recall: 0.6428571428571429\n",
      "F1 Score: 0.75\n",
      "Cohens Kappa Score: 0.6284722222222222\n"
     ]
    }
   ],
   "source": [
    "# Show the Accuracy, Precision, Recall\n",
    "acc_clf = metrics.accuracy_score(y_test, y_pred_clf)\n",
    "prec_clf = metrics.precision_score(y_test, y_pred_clf, pos_label = 'HS')\n",
    "rec_clf = metrics.recall_score(y_test, y_pred_clf, pos_label = 'HS')\n",
    "f1_clf = metrics.f1_score(y_test, y_pred_clf, pos_label = 'HS')\n",
    "kappa_clf = metrics.cohen_kappa_score(y_test, y_pred_clf)\n",
    "\n",
    "print(\"Accuracy:\", acc_clf)\n",
    "print(\"Precision:\", prec_clf)\n",
    "print(\"Recall:\", rec_clf)\n",
    "print(\"F1 Score:\", f1_clf)\n",
    "print(\"Cohens Kappa Score:\", kappa_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kesimpulan\n",
    "Berdasarkan ketiga model yang dibuat, diketahui bahwa akurasi dan presisi tertinggi ada pada **Random Forest** dengan berturut turut **0.83** dan **0.9**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
